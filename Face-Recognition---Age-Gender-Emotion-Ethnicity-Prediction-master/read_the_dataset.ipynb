{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'http://com.dataturks.a96-i23.open.s3.amazonaws.com/2c9fafb06477f4cb0164895548a600a3/66127d05-93eb-498f-bac3-85a19bcbbbc7___2538464.main_image.jpg.jpeg',\n",
       " 'annotation': [{'label': ['Emotion_Happy',\n",
       "    'Age_below20',\n",
       "    'E_White',\n",
       "    'G_Male'],\n",
       "   'notes': '',\n",
       "   'points': [{'x': 0.19876868953386104, 'y': 0.23148148148148148},\n",
       "    {'x': 0.3245382585751979, 'y': 0.45987654320987653}],\n",
       "   'imageWidth': 1300,\n",
       "   'imageHeight': 741},\n",
       "  {'label': ['Emotion_Happy', 'Age_20_30', 'E_White', 'G_ Female'],\n",
       "   'notes': '',\n",
       "   'points': [{'x': 0.6024626209322779, 'y': 0.16049382716049382},\n",
       "    {'x': 0.7361477572559367, 'y': 0.36882716049382713}],\n",
       "   'imageWidth': 1300,\n",
       "   'imageHeight': 741}],\n",
       " 'extras': None,\n",
       " 'metadata': {'first_done_at': 1531657992000,\n",
       "  'last_updated_at': 1531657992000,\n",
       "  'sec_taken': 23,\n",
       "  'last_updated_by': 'HWbICv9u4uSnWrU830DjuF7FfMK2'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = requests.get(data[1]['content']).content\n",
    "\n",
    "with open('pic1.jpg', 'wb') as f:\n",
    "    f.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for i in range(2500):\n",
    "    ls.append(i)\n",
    "    \n",
    "ls.append('Emotion')\n",
    "ls.append('Age')\n",
    "ls.append('Color')\n",
    "ls.append('Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns=ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "for i in range(69, len(data)):\n",
    "    \n",
    "    print(i)\n",
    "    img_data = requests.get(data[i]['content']).content\n",
    "\n",
    "    with open('pic1.jpg', 'wb') as f:\n",
    "        f.write(img_data)\n",
    "        \n",
    "    img = Image.open('pic1.jpg')\n",
    "    \n",
    "    img1 = img.convert('L')\n",
    "    \n",
    "    arr = np.array(img1)\n",
    "    \n",
    "    for j in range(len(data[i]['annotation'])):\n",
    "        \n",
    "        imgWidth = data[i]['annotation'][0]['imageWidth']\n",
    "        imgHeight = data[i]['annotation'][0]['imageHeight']\n",
    "        \n",
    "        x1 = int(data[i]['annotation'][j]['points'][0]['x']*imgWidth)\n",
    "        y1 = int(data[i]['annotation'][j]['points'][0]['y']*imgHeight)\n",
    "        x2 = int(data[i]['annotation'][j]['points'][1]['x']*imgWidth)\n",
    "        y2 = int(data[i]['annotation'][j]['points'][1]['y']*imgHeight)\n",
    "        \n",
    "        arr1 = arr[y1:y2, x1:x2]\n",
    "        img1 = Image.fromarray(arr1)\n",
    "        img1 = img1.resize((50, 50), PIL.Image.ANTIALIAS)\n",
    "        \n",
    "        arr1 = np.array(img1)\n",
    "        \n",
    "        face = []\n",
    "        \n",
    "        for k in range(50):\n",
    "            for l in range(50):\n",
    "                face.append(arr1[k][l])\n",
    "                \n",
    "        for k in data[i]['annotation'][j]['label']:\n",
    "            face.append(k)\n",
    "            \n",
    "        while len(face) < 2504:\n",
    "            face.append(0)\n",
    "        \n",
    "        face = tuple(face)\n",
    "        ls1 = tuple(ls)\n",
    "        \n",
    "        dataset = dataset.append(dict(zip(ls1, face)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'http://com.dataturks.a96-i23.open.s3.amazonaws.com/2c9fafb06477f4cb0164895548a600a3/ab00cf32-c505-4ac0-b7bc-decb3bc18f83___the-lego-store.jpeg',\n",
       " 'annotation': [],\n",
       " 'extras': None,\n",
       " 'metadata': {'first_done_at': 1533196497000,\n",
       "  'last_updated_at': 1533196497000,\n",
       "  'sec_taken': 55,\n",
       "  'last_updated_by': 'HWbICv9u4uSnWrU830DjuF7FfMK2'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
